# -*- coding: utf-8 -*-
"""Comparable_Training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10aCbYORphKGo5t49D0Dc_4PTo3ABRygM
"""

import matplotlib.pyplot as plt
import numpy as np
import os
import tensorflow as tf
from tensorflow import keras
from keras import Sequential
from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization
from keras.applications.vgg16 import VGG16
from keras.applications import ResNet50  # We'll use ResNet50 as AlexNet substitute
from tensorflow.keras.preprocessing import image
from tensorflow.keras.optimizers import RMSprop, Adam
import zipfile

# Set random seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

import zipfile
zip_ref = zipfile.ZipFile('/content/cats_and_dogs_filtered.zip', 'r')
zip_ref.extractall('/content')
zip_ref.close()

# Data generators for cats vs dogs classification
train_ds = keras.utils.image_dataset_from_directory(
    directory='/content/cats_and_dogs_filtered/train',
    labels='inferred',
    label_mode='int',  # Binary classification
    batch_size=32,
    image_size=(224, 224)
)

validation_ds = keras.utils.image_dataset_from_directory(
    directory='/content/cats_and_dogs_filtered/validation',
    labels='inferred',
    label_mode='int',  # Binary classification
    batch_size=32,
    image_size=(224, 224)
)

# Get class names and number of classes
class_names = train_ds.class_names
num_classes = len(class_names)
print(f"Number of classes: {num_classes}")
print(f"Class names: {class_names}")

class_names = train_ds.class_names

# Normalize images
def process(image, label):
    image = tf.cast(image/255.0, tf.float32)
    return image, label

train_ds = train_ds.map(process)
validation_ds = validation_ds.map(process)

# ============================================================================
# MODEL 1: FINE-TUNED VGG16
# ============================================================================

def create_vgg16_model():
    """Create fine-tuned VGG16 model for binary classification"""
    # Load pre-trained VGG16
    vgg_base = VGG16(
        weights='imagenet',
        include_top=False,  # Don't include top classification layer
        input_shape=(224, 224, 3)
    )

    # Freeze all layers in the base model
    for layer in vgg_base.layers:
        layer.trainable = False

    # Print layer info
    print("\nVGG16 Layers:")
    for layer in vgg_base.layers:
        print(f"{layer.name:<20} | Type: {type(layer).__name__:<20} | Trainable: {layer.trainable}")

    # Create new model
    model = Sequential([
        vgg_base,
        Flatten(),
        Dense(512, activation='relu'),
        Dropout(0.5),
        Dense(256, activation='relu'),
        Dropout(0.5),
        Dense(1, activation='sigmoid')  # Binary classification
    ])

    return model

# ============================================================================
# MODEL 2: ALEXNET-INSPIRED MODEL (using ResNet50 as base)
# ============================================================================

def create_alexnet_model():
    """Create AlexNet-inspired model using ResNet50 as base"""
    # Load pre-trained ResNet50 (as AlexNet substitute)
    alexnet_base = ResNet50(
        weights='imagenet',
        include_top=False,
        input_shape=(224, 224, 3)
    )

    # Freeze all layers in the base model
    for layer in alexnet_base.layers:
        layer.trainable = False

    # Print layer info
    print("\nAlexNet-inspired (ResNet50) Layers:")
    for layer in alexnet_base.layers[:10]:  # Show first 10 layers
        print(f"{layer.name:<20} | Type: {type(layer).__name__:<20} | Trainable: {layer.trainable}")
    print("...")

    # Create new model with AlexNet-style dense layers
    model = Sequential([
        alexnet_base,
        Flatten(),
        Dense(4096, activation='relu'),
        Dropout(0.5),
        Dense(4096, activation='relu'),
        Dropout(0.5),
        Dense(1, activation='sigmoid')  # Binary classification
    ])

    return model

# ============================================================================
# MODEL 3: LENET-INSPIRED MODEL (Built from scratch)
# ============================================================================

def create_lenet_model():
    """Create LeNet-inspired model from scratch"""
    model = Sequential([
        # First convolutional layer
        Conv2D(32, (5, 5), activation='relu', input_shape=(224, 224, 3)),
        MaxPooling2D(2, 2),

        # Second convolutional layer
        Conv2D(64, (5, 5), activation='relu'),
        MaxPooling2D(2, 2),

        # Third convolutional layer (added for better performance on larger images)
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D(2, 2),

        # Flatten and dense layers
        Flatten(),
        Dense(512, activation='relu'),
        Dropout(0.5),
        Dense(256, activation='relu'),
        Dropout(0.5),
        Dense(1, activation='sigmoid')  # Binary classification
    ])

    return model

# ============================================================================
# MODEL TRAINING AND EVALUATION
# ============================================================================

def train_and_evaluate_model(model, model_name, epochs=10):
    """Train and evaluate a model"""
    print(f"\n{'='*50}")
    print(f"Training {model_name}")
    print(f"{'='*50}")

    # Compile model for binary classification
    model.compile(
        optimizer=RMSprop(learning_rate=1e-5),  # Using same learning rate as original
        loss='binary_crossentropy',
        metrics=['accuracy']
    )

    # Print model summary
    print(f"\n{model_name} Architecture:")
    model.summary()

    # Train model
    history = model.fit(
        train_ds,
        epochs=epochs,
        validation_data=validation_ds,
        verbose=1
    )

    return history

def plot_training_history(histories, model_names):
    """Plot training history for all models"""
    plt.figure(figsize=(15, 5))

    # Plot accuracy
    plt.subplot(1, 2, 1)
    for history, name in zip(histories, model_names):
        plt.plot(history.history['accuracy'], label=f'{name} Train')
        plt.plot(history.history['val_accuracy'], label=f'{name} Val')
    plt.title('Model Accuracy Comparison')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)

    # Plot loss
    plt.subplot(1, 2, 2)
    for history, name in zip(histories, model_names):
        plt.plot(history.history['loss'], label=f'{name} Train')
        plt.plot(history.history['val_loss'], label=f'{name} Val')
    plt.title('Model Loss Comparison')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()

print("Creating models...")
vgg_model = create_vgg16_model()
alexnet_model = create_alexnet_model()
lenet_model = create_lenet_model()

# Train models
epochs = 10
histories = []
model_names = ['VGG16', 'AlexNet-inspired', 'LeNet-inspired']
models = [vgg_model, alexnet_model, lenet_model]

for model, name in zip(models, model_names):
    history = train_and_evaluate_model(model, name, epochs)
    histories.append(history)

# Plot comparison
plot_training_history(histories, model_names)

# ============================================================================
# MODEL EVALUATION AND COMPARISON
# ============================================================================

def evaluate_models(models, model_names):
    """Evaluate all models and compare performance"""
    print(f"\n{'='*60}")
    print("FINAL MODEL COMPARISON")
    print(f"{'='*60}")

    results = []
    for model, name in zip(models, model_names):
        # Evaluate on validation set
        val_loss, val_accuracy = model.evaluate(validation_ds, verbose=0)
        results.append({
            'Model': name,
            'Validation Loss': val_loss,
            'Validation Accuracy': val_accuracy
        })
        print(f"{name:<20} | Val Loss: {val_loss:.4f} | Val Accuracy: {val_accuracy:.4f}")

    return results

# Evaluate all models
results = evaluate_models(models, model_names)

# ============================================================================
# PREDICTION EXAMPLE
# ============================================================================

def predict_sample_images(models, model_names, class_names, num_samples=3):
    """Make predictions on multiple sample images"""
    # Get a batch from validation dataset
    for images, labels in validation_ds.take(1):
        num_samples = min(num_samples, len(images))

        print(f"\n{'='*60}")
        print(f"SAMPLE PREDICTIONS")
        print(f"{'='*60}")

        # Process multiple samples
        for sample_idx in range(num_samples):
            sample_image = images[sample_idx]
            true_label_idx = labels[sample_idx].numpy()
            true_label = class_names[true_label_idx]

            # Expand dimensions for prediction
            sample_image_batch = tf.expand_dims(sample_image, 0)

            print(f"\nSample {sample_idx + 1} - True Label: {true_label}")
            print("-" * 40)

            # Make predictions with all models
            plt.figure(figsize=(15, 5))

            for i, (model, name) in enumerate(zip(models, model_names)):
                prediction = model.predict(sample_image_batch, verbose=0)
                prediction_prob = prediction[0][0]
                predicted_class = class_names[1] if prediction_prob > 0.5 else class_names[0]
                confidence = prediction_prob if prediction_prob > 0.5 else 1 - prediction_prob

                plt.subplot(1, 3, i+1)
                plt.imshow(sample_image)
                plt.title(f'{name}\nPredicted: {predicted_class}\nConfidence: {confidence:.3f}')
                plt.axis('off')

                print(f"{name:<20} | Predicted: {predicted_class:<4} | Confidence: {confidence:.3f}")

            plt.tight_layout()
            plt.show()

        break

# Make sample predictions
predict_sample_images(models, model_names, class_names, num_samples=2)

#######################################################################################################

!pip install tensorflow

import matplotlib.pyplot as plt
import numpy as np
import os
import tensorflow as tf
from tensorflow import keras
from keras import Sequential
from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization
from keras.applications.vgg16 import VGG16
from keras.applications import ResNet50  # We'll use ResNet50 as AlexNet substitute
from tensorflow.keras.preprocessing import image
from tensorflow.keras.optimizers import RMSprop, Adam
import zipfile

# Set random seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

import zipfile
zip_ref = zipfile.ZipFile('/content/Sports_Labelling.zip', 'r')
zip_ref.extractall('/content')
zip_ref.close()

# Data generators for 100 sports classification
train_ds = keras.utils.image_dataset_from_directory(
    directory='/content/train',  # Adjust path as needed
    labels='inferred',
    label_mode='categorical',  # Changed to categorical for multi-class
    batch_size=32,
    image_size=(224, 224),
    validation_split=0.2,
    subset='training',
    seed=42
)

validation_ds = keras.utils.image_dataset_from_directory(
    directory='/content/valid',  # Adjust path as needed
    labels='inferred',
    label_mode='categorical',
    batch_size=32,
    image_size=(224, 224),
    validation_split=0.2,
    subset='validation',
    seed=42
)

# Get number of classes and store class names before preprocessing
class_names = train_ds.class_names
num_classes = len(class_names)
print(f"Number of sports classes: {num_classes}")
print(f"Class names: {class_names[:10]}...")

# Normalize images
def process(image, label):
    image = tf.cast(image/255.0, tf.float32)
    return image, label

train_ds = train_ds.map(process)
validation_ds = validation_ds.map(process)

# ============================================================================
# MODEL 1: FINE-TUNED VGG16
# ============================================================================

def create_vgg16_model(num_classes):
    """Create fine-tuned VGG16 model"""
    # Load pre-trained VGG16
    vgg_base = VGG16(
        weights='imagenet',
        include_top=False,  # Don't include top classification layer
        input_shape=(224, 224, 3)
    )

    # Freeze all layers in the base model
    for layer in vgg_base.layers:
        layer.trainable = False

    # Print layer info
    print("\nVGG16 Layers:")
    for layer in vgg_base.layers:
        print(f"{layer.name:<20} | Type: {type(layer).__name__:<20} | Trainable: {layer.trainable}")

    # Create new model
    model = Sequential([
        vgg_base,
        Flatten(),
        Dense(512, activation='relu'),
        Dropout(0.5),
        Dense(256, activation='relu'),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])

    return model

# ============================================================================
# MODEL 2: ALEXNET-INSPIRED MODEL (using ResNet50 as base)
# ============================================================================

def create_alexnet_model(num_classes):
    """Create AlexNet-inspired model using ResNet50 as base"""
    # Load pre-trained ResNet50 (as AlexNet substitute)
    alexnet_base = ResNet50(
        weights='imagenet',
        include_top=False,
        input_shape=(224, 224, 3)
    )

    # Freeze all layers in the base model
    for layer in alexnet_base.layers:
        layer.trainable = False

    # Print layer info
    print("\nAlexNet-inspired (ResNet50) Layers:")
    for layer in alexnet_base.layers[:10]:  # Show first 10 layers
        print(f"{layer.name:<20} | Type: {type(layer).__name__:<20} | Trainable: {layer.trainable}")
    print("...")

    # Create new model with AlexNet-style dense layers
    model = Sequential([
        alexnet_base,
        Flatten(),
        Dense(4096, activation='relu'),
        Dropout(0.5),
        Dense(4096, activation='relu'),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])

    return model

# ============================================================================
# MODEL 3: LENET-INSPIRED MODEL (Built from scratch)
# ============================================================================

def create_lenet_model(num_classes):
    """Create LeNet-inspired model from scratch"""
    model = Sequential([
        # First convolutional layer
        Conv2D(32, (5, 5), activation='relu', input_shape=(224, 224, 3)),
        MaxPooling2D(2, 2),

        # Second convolutional layer
        Conv2D(64, (5, 5), activation='relu'),
        MaxPooling2D(2, 2),

        # Third convolutional layer (added for better performance on larger images)
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D(2, 2),

        # Flatten and dense layers
        Flatten(),
        Dense(512, activation='relu'),
        Dropout(0.5),
        Dense(256, activation='relu'),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])

    return model

# ============================================================================
# MODEL TRAINING AND EVALUATION
# ============================================================================

def train_and_evaluate_model(model, model_name, epochs=10):
    """Train and evaluate a model"""
    print(f"\n{'='*50}")
    print(f"Training {model_name}")
    print(f"{'='*50}")

    # Compile model
    model.compile(
        optimizer=RMSprop(learning_rate=1e-4),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    # Print model summary
    print(f"\n{model_name} Architecture:")
    model.summary()

    # Train model
    history = model.fit(
        train_ds,
        epochs=epochs,
        validation_data=validation_ds,
        verbose=1
    )

    return history

def plot_training_history(histories, model_names):
    """Plot training history for all models"""
    plt.figure(figsize=(15, 5))

    # Plot accuracy
    plt.subplot(1, 2, 1)
    for history, name in zip(histories, model_names):
        plt.plot(history.history['accuracy'], label=f'{name} Train')
        plt.plot(history.history['val_accuracy'], label=f'{name} Val')
    plt.title('Model Accuracy Comparison')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)

    # Plot loss
    plt.subplot(1, 2, 2)
    for history, name in zip(histories, model_names):
        plt.plot(history.history['loss'], label=f'{name} Train')
        plt.plot(history.history['val_loss'], label=f'{name} Val')
    plt.title('Model Loss Comparison')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()

# ============================================================================
# MAIN EXECUTION
# ============================================================================

# Create models
print("Creating models...")
vgg_model = create_vgg16_model(num_classes)
alexnet_model = create_alexnet_model(num_classes)
lenet_model = create_lenet_model(num_classes)

# Train models
epochs = 50
histories = []
model_names = ['VGG16', 'AlexNet-inspired', 'LeNet-inspired']
models = [vgg_model, alexnet_model, lenet_model]

for model, name in zip(models, model_names):
    history = train_and_evaluate_model(model, name, epochs)
    histories.append(history)

# Plot comparison
plot_training_history(histories, model_names)

# ============================================================================
# MODEL EVALUATION AND COMPARISON
# ============================================================================

def evaluate_models(models, model_names):
    """Evaluate all models and compare performance"""
    print(f"\n{'='*60}")
    print("FINAL MODEL COMPARISON")
    print(f"{'='*60}")

    results = []
    for model, name in zip(models, model_names):
        # Evaluate on validation set
        val_loss, val_accuracy = model.evaluate(validation_ds, verbose=0)
        results.append({
            'Model': name,
            'Validation Loss': val_loss,
            'Validation Accuracy': val_accuracy
        })
        print(f"{name:<20} | Val Loss: {val_loss:.4f} | Val Accuracy: {val_accuracy:.4f}")

    return results

# Evaluate all models
results = evaluate_models(models, model_names)

# ============================================================================
# PREDICTION EXAMPLE
# ============================================================================

def predict_sample_image(models, model_names, class_names):
    """Make predictions on a sample image"""
    # Get a batch from validation dataset
    for images, labels in validation_ds.take(1):
        sample_image = images[0]
        true_label = class_names[tf.argmax(labels[0]).numpy()]

        # Expand dimensions for prediction
        sample_image_batch = tf.expand_dims(sample_image, 0)

        print(f"\n{'='*60}")
        print(f"SAMPLE PREDICTION - True Label: {true_label}")
        print(f"{'='*60}")

        # Make predictions with all models
        plt.figure(figsize=(15, 5))

        for i, (model, name) in enumerate(zip(models, model_names)):
            prediction = model.predict(sample_image_batch, verbose=0)
            predicted_class = class_names[tf.argmax(prediction[0]).numpy()]
            confidence = tf.nn.softmax(prediction[0]).numpy().max()

            plt.subplot(1, 3, i+1)
            plt.imshow(sample_image)
            plt.title(f'{name}\nPredicted: {predicted_class}\nConfidence: {confidence:.3f}')
            plt.axis('off')

        plt.tight_layout()
        plt.show()
        break

# Make sample predictions
predict_sample_image(models, model_names, class_names)

import random

def predict_sample_image(models, model_names, class_names):
    """Make predictions on a randomly selected sample image"""
    # Get a batch from validation dataset
    for images, labels in validation_ds.take(1):
        # Randomly select an image from the batch
        batch_size = len(images)
        random_index = random.randint(0, batch_size - 1)

        sample_image = images[random_index]
        true_label = class_names[tf.argmax(labels[random_index]).numpy()]

        # Expand dimensions for prediction
        sample_image_batch = tf.expand_dims(sample_image, 0)

        print(f"\n{'='*60}")
        print(f"SAMPLE PREDICTION - True Label: {true_label}")
        print(f"Random Index: {random_index} out of batch size {batch_size}")
        print(f"{'='*60}")

        # Make predictions with all models
        plt.figure(figsize=(15, 5))

        for i, (model, name) in enumerate(zip(models, model_names)):
            prediction = model.predict(sample_image_batch, verbose=0)
            predicted_class = class_names[tf.argmax(prediction[0]).numpy()]
            confidence = tf.nn.softmax(prediction[0]).numpy().max()

            plt.subplot(1, 3, i+1)
            plt.imshow(sample_image)
            plt.title(f'{name}\nPredicted: {predicted_class}\nConfidence: {confidence:.3f}')
            plt.axis('off')

        plt.tight_layout()
        plt.show()
        break

# Usage examples:
predict_sample_image(models, model_names, class_names)

predict_sample_image(models, model_names, class_names)

predict_sample_image(models, model_names, class_names)









# ============================================================================
# MODEL EVALUATION AND COMPARISON
# ============================================================================

def evaluate_models(models, model_names):
    """Evaluate all models and compare performance"""
    print(f"\n{'='*60}")
    print("FINAL MODEL COMPARISON")
    print(f"{'='*60}")

    results = []
    for model, name in zip(models, model_names):
        # Evaluate on validation set
        val_loss, val_accuracy = model.evaluate(validation_ds, verbose=0)
        results.append({
            'Model': name,
            'Validation Loss': val_loss,
            'Validation Accuracy': val_accuracy
        })
        print(f"{name:<20} | Val Loss: {val_loss:.4f} | Val Accuracy: {val_accuracy:.4f}")

    return results

# Evaluate all models
results = evaluate_models(models, model_names)

# ============================================================================
# PREDICTION EXAMPLE
# ============================================================================

def predict_sample_image(models, model_names, class_names):
    """Make predictions on a sample image"""
    # Get a batch from validation dataset
    for images, labels in validation_ds.take(1):
        sample_image = images[0]
        true_label = class_names[tf.argmax(labels[0]).numpy()]

        # Expand dimensions for prediction
        sample_image_batch = tf.expand_dims(sample_image, 0)

        print(f"\n{'='*60}")
        print(f"SAMPLE PREDICTION - True Label: {true_label}")
        print(f"{'='*60}")

        # Make predictions with all models
        plt.figure(figsize=(15, 5))

        for i, (model, name) in enumerate(zip(models, model_names)):
            prediction = model.predict(sample_image_batch, verbose=0)
            predicted_class = class_names[tf.argmax(prediction[0]).numpy()]
            confidence = tf.nn.softmax(prediction[0]).numpy().max()

            plt.subplot(1, 3, i+1)
            plt.imshow(sample_image)
            plt.title(f'{name}\nPredicted: {predicted_class}\nConfidence: {confidence:.3f}')
            plt.axis('off')

        plt.tight_layout()
        plt.show()
        break

class_names = train_ds.class_names

# Make sample predictions
predict_sample_image(models, model_names, class_names)

